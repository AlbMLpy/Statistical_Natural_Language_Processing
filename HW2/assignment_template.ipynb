{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b09d7a19-5848-43f4-9d91-f35d4e8614b0",
      "metadata": {
        "id": "b09d7a19-5848-43f4-9d91-f35d4e8614b0"
      },
      "source": [
        "# 1. Information about the submission"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e37cb5bb-f3d0-4c11-a1dc-2490a208fcd3",
      "metadata": {
        "id": "e37cb5bb-f3d0-4c11-a1dc-2490a208fcd3"
      },
      "source": [
        "## 1.1 Name and number of the assignment "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e9d00b8-f3e5-4a44-bcc6-35cdd60767a9",
      "metadata": {
        "id": "4e9d00b8-f3e5-4a44-bcc6-35cdd60767a9"
      },
      "source": [
        "Albert Sayapin, Assignment 1."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64ba7f63-66ec-4691-a5d2-17f4679e298d",
      "metadata": {
        "id": "64ba7f63-66ec-4691-a5d2-17f4679e298d"
      },
      "source": [
        "## 1.2 Student name"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc8a4e09-62cc-43fd-a7a7-3e9d55ec13b2",
      "metadata": {
        "id": "cc8a4e09-62cc-43fd-a7a7-3e9d55ec13b2"
      },
      "source": [
        "Albert Sayapin"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a46ab45-d215-41af-b910-63ff4a215a07",
      "metadata": {
        "id": "8a46ab45-d215-41af-b910-63ff4a215a07"
      },
      "source": [
        "## 1.3 Codalab user ID"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b15cd6b5-8e20-4287-b6ea-a7b0904b355a",
      "metadata": {
        "id": "b15cd6b5-8e20-4287-b6ea-a7b0904b355a"
      },
      "source": [
        "***Enter here** your Codalab user ID used to submit your run to shared task*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70456c74-8e1f-4da0-bebe-fbceee169115",
      "metadata": {
        "id": "70456c74-8e1f-4da0-bebe-fbceee169115"
      },
      "source": [
        "## 1.4 Additional comments"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b810ac6-7739-4f7f-8bea-dbf1198570ea",
      "metadata": {
        "id": "6b810ac6-7739-4f7f-8bea-dbf1198570ea"
      },
      "source": [
        "***Enter here** any additional comments which you would like to communicate to a TA who is going to grade this work not related to the content of your submission.*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1af498ab-3c00-4d36-a962-c947862fede8",
      "metadata": {
        "id": "1af498ab-3c00-4d36-a962-c947862fede8"
      },
      "source": [
        "# 2. Technical Report"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b3c18a6-868b-4357-a308-7f6dff05c3d0",
      "metadata": {
        "id": "9b3c18a6-868b-4357-a308-7f6dff05c3d0"
      },
      "source": [
        "*Use Section 2 to describe results of your experiments as you would do writing a paper about your results. DO NOT insert code in this part. Only insert plots and tables summarizing results as needed. Use formulas if needed do described your methodology. The code is provided in Section 3.*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "061f71b9-114a-4cb0-b531-5711970317bf",
      "metadata": {
        "id": "061f71b9-114a-4cb0-b531-5711970317bf"
      },
      "source": [
        "## 2.1 Methodology "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c327f43e-ed30-4279-bba2-a97b2f8ef9e3",
      "metadata": {
        "id": "c327f43e-ed30-4279-bba2-a97b2f8ef9e3"
      },
      "source": [
        "***Enter here** a detailed description of the method used in your submission(s) to Codalab. The description should be at least 2-4 paragraphs featuring the following: type of the model, meta-parameters, how did you select meta-parameters, any further modifications of the out-of-the-box solutions, etc. The text is markdown and you can use math environment to write formulas:* \n",
        "\n",
        "$\\hat{y}=\\beta_0 + \\sum^p_{j=1} x_j \\beta_j$\n",
        "\n",
        "Also you can insert images as needed:\n",
        "\n",
        "![image](https://upload.wikimedia.org/wikipedia/commons/6/6d/Exam_pass_logistic_curve.jpeg)\n",
        "\n",
        "*This part of the should contain description of all methods that you tried and, most importantly, that worked the best for you. Here you can include some tricks of your preprocessing, description of the models and motivation of their usage, the description of the training process details (train-test split, cross-validation, etc.). So, everything valuable that will help us to understand the scope of your work and reproduce your pipeline*\n",
        "\n",
        "*The 'innovativeness' scores will be assigned based on the content of this part. In case you just use a 'drop-in' baseline model these scores will be low. In case you made some clever modification of the model which improves the result this score will be low. However, it does not make sense do describe some modifications which are creative but does not work at all. Try different approaches, models, play with preprocessing, hyperparameters, etc. It is OK to reimplement some already existing approach. It is OK that some of your experiments did not work as you expected. Show us that you used your creativity and ran several experiments.*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afe27e49-10c7-4c12-adea-48b0a05a5681",
      "metadata": {
        "id": "afe27e49-10c7-4c12-adea-48b0a05a5681"
      },
      "source": [
        "## 2.2 Discussion of results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5b1c84c-c261-46b5-a009-0f2bc4002752",
      "metadata": {
        "id": "b5b1c84c-c261-46b5-a009-0f2bc4002752"
      },
      "source": [
        "***Enter here** a discussion of results and a summary of the experiment. Here we want to see the final table with comparison of the baseline and all tried approaches you decided to report. Even if some method did not bring you to the top of the leaderboard, you should nevertheless indicate this result and a discussion, why, in your opinion, some approach worked and another failed. Interesting findings in the discussion will be a plus.*\n",
        "\n",
        "Method | Precision | Recall\n",
        "--- | --- | ---\n",
        "Baseline | 0.88 | 0.77\n",
        "My great method 1 | 0.99 | 0.11\n",
        "My great method 2 | 0.90 | 0.90\n",
        "\n",
        "*If relevant insert plots and historgams in this section e.g. testing variation of the score with respect to some parameters e.g. learning rate or size of the input dataset, etc. Please do not use code to generate plots, instead just insert images as shown below. Plots could be generated from code in Section 3. *\n",
        "\n",
        "![image](https://upload.wikimedia.org/wikipedia/commons/thumb/d/d2/Sine_and_Cosine.svg/640px-Sine_and_Cosine.svg.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "194fecf1-e044-4210-a54b-aefbf4b4eebe",
      "metadata": {
        "id": "194fecf1-e044-4210-a54b-aefbf4b4eebe"
      },
      "source": [
        "# 3. Code"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a33ff9bd-62c6-4a63-8600-b1651420fee1",
      "metadata": {
        "id": "a33ff9bd-62c6-4a63-8600-b1651420fee1"
      },
      "source": [
        "*Enter here all code used to produce your results submitted to Codalab. Add some comments and subsections to navigate though your solution.*\n",
        "\n",
        "*In this part you are expected to develop yourself a solution of the task and provide a reproducible code:*\n",
        "- *Using Python 3;*\n",
        "- *Contains code for installation of all dependencies;*\n",
        "- *Contains code for downloading of all the datasets used*;\n",
        "- *Contains the code for reproducing your results (in other words, if a tester downloads your notebook she should be able to run cell-by-cell the code and obtain your experimental results as described in the methodology section)*.\n",
        "\n",
        "\n",
        "*As a result, you code will be graded according to these criteria:*\n",
        "- ***Readability**: your code should be well-structured preferably with indicated parts of your approach (Preprocessing, Model training, Evaluation, etc.).*\n",
        "- ***Reproducibility**: your code should be reproduced without any mistakes with “Run all” mode (obtaining experimental part).*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dff93e37-3a24-40ab-87db-16b537aad3f6",
      "metadata": {
        "id": "dff93e37-3a24-40ab-87db-16b537aad3f6"
      },
      "source": [
        "## 3.1 Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73daa932-114b-4e28-9141-13b57c729435",
      "metadata": {
        "id": "73daa932-114b-4e28-9141-13b57c729435",
        "outputId": "abf866c8-b599-458d-cc0d-f5f09f5c6b8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /Users/sasha/anaconda3/lib/python3.7/site-packages (2.2.1)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /Users/sasha/anaconda3/lib/python3.7/site-packages (from spacy) (0.9.6)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /Users/sasha/anaconda3/lib/python3.7/site-packages (from spacy) (0.1.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /Users/sasha/anaconda3/lib/python3.7/site-packages (from spacy) (0.3.0)\n",
            "Requirement already satisfied: thinc<7.2.0,>=7.1.1 in /Users/sasha/anaconda3/lib/python3.7/site-packages (from spacy) (7.1.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/sasha/anaconda3/lib/python3.7/site-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/sasha/anaconda3/lib/python3.7/site-packages (from spacy) (3.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/sasha/anaconda3/lib/python3.7/site-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/sasha/anaconda3/lib/python3.7/site-packages (from spacy) (2.25.1)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /Users/sasha/anaconda3/lib/python3.7/site-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /Users/sasha/anaconda3/lib/python3.7/site-packages (from spacy) (1.20.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/sasha/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /Users/sasha/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/sasha/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/sasha/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /Users/sasha/anaconda3/lib/python3.7/site-packages (from thinc<7.2.0,>=7.1.1->spacy) (4.59.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install spacy\n",
        "# and some other your dependenciesb"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b3c19fa-f883-4675-9506-85c4f02f0af9",
      "metadata": {
        "id": "1b3c19fa-f883-4675-9506-85c4f02f0af9"
      },
      "source": [
        "## 3.2 Download the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f366b0f-7d0b-44e0-bb82-0d82c3ea1bb1",
      "metadata": {
        "id": "8f366b0f-7d0b-44e0-bb82-0d82c3ea1bb1",
        "outputId": "9421f542-f14b-4431-97f6-3e8e0878e376"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2021-10-26 16:59:42--  http://panchenko.me/data/toxic/tagger-dstc8/dstc_conll_train.txt\n",
            "Resolving panchenko.me (panchenko.me)... 130.104.253.4\n",
            "Connecting to panchenko.me (panchenko.me)|130.104.253.4|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 29941431 (29M) [text/plain]\n",
            "Saving to: <<dstc_conll_train.txt>>\n",
            "\n",
            "dstc_conll_train.tx 100%[===================>]  28.55M  8.97MB/s    in 3.4s    \n",
            "\n",
            "2021-10-26 16:59:46 (8.32 MB/s) - <<dstc_conll_train.txt>> saved [29941431/29941431]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://panchenko.me/data/toxic/tagger-dstc8/dstc_conll_train.txt\n",
        "# if some needed file is not in the public domain use google drive or other free hosting to make them available"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed8aa6f0-79e0-4c7d-b6bc-2dcd48382af2",
      "metadata": {
        "id": "ed8aa6f0-79e0-4c7d-b6bc-2dcd48382af2",
        "outputId": "86035bb3-7bf7-4c98-ac32-87456dc1196e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-DOCSTART- O\n",
            " \n",
            "I O\n",
            "'m O\n",
            "looking O\n",
            "for O\n",
            "a O\n",
            "place O\n",
            "to O\n",
            "eat O\n",
            ". O\n",
            " \n",
            "What O\n",
            "are O\n",
            "you O\n",
            "in O\n",
            "the O\n",
            "mood O\n",
            "for O\n",
            ": O\n"
          ]
        }
      ],
      "source": [
        "!head -20 dstc_conll_train.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "791dc0e7-337d-46ad-96a3-543a732f19e2",
      "metadata": {
        "id": "791dc0e7-337d-46ad-96a3-543a732f19e2"
      },
      "source": [
        "## 3.3 Preprocessing "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b71a4653-86f2-448a-a2c4-17c02c1ba940",
      "metadata": {
        "id": "b71a4653-86f2-448a-a2c4-17c02c1ba940",
        "outputId": "dc0d1d60-472e-4ac1-a25a-8b503b0b7b03",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-DOCSTART- I 'm looking for a place to eat . What are you in the mood for : Mexican , Chinese , or something else ? Sushi sounds good right now . Which city do you want to eat in ? Somewhere affordable , that sells alcohol in SF . 2g Japanese Brasserie is a nice sushi restaurant in San Francisco . Can I call them ? Is there live music ? There is no live music , and their phone number is 415-292-9997 . Are there any other restauarnts nearby ? Akira Japanese Restaurant is also a sushi restaurant in San Francisco . That sounds good . Would you like to make a reservation ? Yes I would like to make a reservation . What time would you like the reservation ? Lets eat at five pm . Can you confirm the details : Booking a table for 2 people , at Akira Japanese Restaurant in San Francisco , today at 5 pm . Actually is is for six people . Okay. Can you confirm the details : Booking a table for\n"
          ]
        }
      ],
      "source": [
        "# Get some text from the input data\n",
        "\n",
        "f = open(\"dstc_conll_train.txt\")\n",
        "\n",
        "tokens = []\n",
        "for i, line in enumerate(f):\n",
        "    if i > 200: break\n",
        "    try:\n",
        "        token, tag = line.split()\n",
        "        tokens.append(token)\n",
        "    except:\n",
        "        continue\n",
        "        \n",
        "text = \" \".join(tokens)  \n",
        "\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23773d4e-e8d7-4e56-9610-4ee61b38c65a",
      "metadata": {
        "id": "23773d4e-e8d7-4e56-9610-4ee61b38c65a"
      },
      "source": [
        "## 3.4 My method of text processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4aa2274-477a-46e6-95ff-ec98e633ab35",
      "metadata": {
        "id": "f4aa2274-477a-46e6-95ff-ec98e633ab35",
        "outputId": "f1ee1349-734b-462e-d934-32c3498ccddc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Noun phrases: ['a place', 'What', 'you', 'the mood', 'Mexican', 'something', 'Sushi', 'you', 'alcohol', 'SF', 'g', 'Japanese Brasserie', 'a nice sushi restaurant', 'San Francisco', 'I', 'them', 'live music', 'no live music', 'their phone number', 'any other restauarnts', 'Akira Japanese Restaurant', 'a sushi restaurant', 'San Francisco', 'you', 'a reservation', 'I', 'a reservation', 'you', 'the reservation', 'Lets', 'five pm', 'you', 'the details', 'a table', '2 people', 'Akira Japanese Restaurant', 'San Francisco', '5 pm', 'six people', 'you', 'the details', 'a table']\n",
            "Verbs: ['look', 'eat', 'sound', 'want', 'eat', 'sell', 'call', 'sound', 'like', 'make', 'like', 'make', 'like', 'eat', 'confirm', 'book', 'confirm', 'book']\n",
            "Mexican NORP\n",
            "Chinese NORP\n",
            "SF GPE\n",
            "2 CARDINAL\n",
            "Japanese NORP\n",
            "Brasserie PERSON\n",
            "San Francisco GPE\n",
            "415 CARDINAL\n",
            "Japanese NORP\n",
            "Restaurant PERSON\n",
            "San Francisco GPE\n",
            "five pm TIME\n",
            "2 CARDINAL\n",
            "Akira Japanese Restaurant ORG\n",
            "San Francisco GPE\n",
            "today DATE\n",
            "5 pm TIME\n",
            "six CARDINAL\n"
          ]
        }
      ],
      "source": [
        "# Perform some processing of the text \n",
        "\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(text)\n",
        "\n",
        "# Analyze syntax\n",
        "print(\"Noun phrases:\", [chunk.text for chunk in doc.noun_chunks])\n",
        "print(\"Verbs:\", [token.lemma_ for token in doc if token.pos_ == \"VERB\"])\n",
        "\n",
        "# Find named entities, phrases and concepts\n",
        "for entity in doc.ents:\n",
        "    print(entity.text, entity.label_)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "assignment-template.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
